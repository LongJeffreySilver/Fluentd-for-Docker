#Just in case of debug
#<system>
  #log_level debug
#</system>

<source>
  @type systemd
  @id source_systemd
  path /var/log/journal
  <storage>
    @type local
    persistent true
    path /fluentd/log/fluentd-journal-pos.json
  </storage>
  <entry>
    fields_strip_underscores true #If true, strip leading underscores from all non-mapped fields. Defaults to false.
    fields_lowercase true #If true, lowercase all non-mapped fields. Defaults to false.
  </entry>
  tag systemd
</source>

<source>
  @type tail
  @id source_syslog
  path /var/log/syslog
  pos_file /fluentd/log/fluentd-syslog.pos
  tag syslog
  format syslog
</source>

#Exponer métricas en formato Prometheus mediante HTTP para que las scrapee el propio Prometheus. NO hace falta un "match" porque
#es el propio Prometheus el que se encarga de venir a buscarlas.
<source>
  @type prometheus
  @id source_prometheus
  # La dirección y puerto donde se expondrán las métricas.
  # Por defecto las métricas estarán disponibles en http://localhost:24231/metrics y se pueden ver si se mapea el puerto en el contenedor
  # aunque para el funcionamiento normal no es necesario.
  bind 0.0.0.0
  port 24231
</source>

#Metricas internas de Fluentd
<source>
  @type monitor_agent
  @id source_in_monitor_agent
  tag internal_metrics_fluentd
  bind 0.0.0.0
  port 24220
  emit_interval 20
</source>

<source>
  @type exec
  @id source_exec_metric_script
  command /fluentd/scripts/health_metrics.py
  tag system.metrics
  run_interval 5
  #Parece que la versión moderna de exec ya no usa "format", si no "parse"
  <parse>
    @type json
  </parse>
</source>


# Como los datos vienen en formato string, hay que hacer un parseo a float, si no, prometheus no lo entiende.
<filter system.metrics>
  @type typecast
  @id filter_parse_string_to_float_host_metrics
  types cpu_usage:float,memory_mb:float
</filter>

<filter internal_metrics_fluentd>
  @type typecast
  @id filter_parse_string_to_float_fluentd_metrics
  types buffer_queue_length:float,buffer_total_queued_size:float,retry_count:float
</filter>

#filtro para systemd
#<filter systemd>
  #@type systemd_entry
  #systemd: {"PRIORITY":"6","_UID":"1000","_SELINUX_CONTEXT":"unconfined\n","_AUDIT_SESSION":"2","_AUDIT_LOGINUID":"1000","_SYSTEMD_OWNER_UID":"1000","_SYSTEMD_UNIT":"user@1000.service","_SYSTEMD_SLICE":"user-1000.slice",
  #"_BOOT_ID":"b629f6a25ff14514ad8f43edcf76c2f0","_MACHINE_ID":"95b467cd3bc24d0bb8630c317f3571bd","_HOSTNAME":"user","_TRANSPORT":"syslog",
  #"_CAP_EFFECTIVE":"1ffffffffff","SYSLOG_FACILITY":"10","SYSLOG_IDENTIFIER":"sudo","_COMM":"sudo","_EXE":"/usr/bin/sudo",
  #"_SYSTEMD_CGROUP":"/user.slice/user-1000.slice/user@1000.service/app.slice/app-org.gnome.Terminal.slice/vte-spawn-b9147130-77ef-4fe6-acc1-552017c4b58c.scope",
  #"_SYSTEMD_USER_UNIT":"vte-spawn-b9147130-77ef-4fe6-acc1-552017c4b58c.scope","_SYSTEMD_USER_SLICE":"app-org.gnome.Terminal.slice",
  #"_SYSTEMD_INVOCATION_ID":"cd7096106b0f4d64be9234322cb714a0","MESSAGE":"pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)",
  #"_GID":"0","_CMDLINE":"sudo docker logs -f fluentd_prueba_container","SYSLOG_TIMESTAMP":"Dec 20 10:55:57 ","_PID":"9021",
  #"_SOURCE_REALTIME_TIMESTAMP":"1734688557949290"}
#   field_map {} #ver los parámeros que quiero
#   field_map_strict false
#   fields_lowercase true
#   fields_strip_underscores true
# </filter>


<filter syslog>
#syslog: {"host":"user","ident":"avahi-daemon","pid":"614","message":"New relevant interface vethc5330ac.IPv6 for mDNS."}
#syslog: {"host":"user","ident":"avahi-daemon","pid":"614","message":"Registering new address record for fe80::fc60:22ff:fef3:eac3 on vethc5330ac.*."}

</filter>


# Mapear a Prometheus. 
# OJO: label_keys y labels_from_record van a nivel de <match>, no dentro de <metric>.
<match system.metrics>
  @type prometheus
  @id match_host_system_metrics_to_prometheus

  <metric>
    name system_cpu_usage
    type gauge
    desc is the CPU usage percentage
    key cpu_usage
  </metric>

  <metric>
    name system_memory_available_mb
    type gauge
    desc is the memory available in MB
    key memory_mb
  </metric>
</match>

# Metricas internas de Fluentd
<match internal_metrics_fluentd>
  @type prometheus
  @id match_metric_agent_to_prometheus

  <metric>
    name fluentd_output_status_buffer_queue_length
    type gauge
    desc is the length of the buffer queue for outputs
    key buffer_queue_length
  </metric>

  <metric>
    name fluentd_output_status_retry_count
    type counter
    desc is the number of retries
    key retry_count
  </metric>

  <metric>
    name fluentd_buffer_total_queued_size
    type gauge
    desc is the total queue size in bytes
    key buffer_total_queued_size
  </metric>
</match>

# Se puede añadir otra fuente con in_tail apuntando a /var/lib/docker/containers/*/*.log y aplicar el filtro docker_metadata.

<match systemd>
  @type stdout
  @id match_systemd_to_stdout
</match>

#Los logs se van a guardar en un fichero para que FileBeat pueda leerlos y enviarlos a Kafka
<match syslog>
  @type file
  @id match_syslog_to_stdout
  path /fluentd/log/syslog_output.log
  append  true
  <buffer>
    flush_mode inmediate
  </buffer>
</match>

